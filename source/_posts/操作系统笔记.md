---
title: 操作系统笔记
date: 2022-01-13 19:44:24
tags: 操作系统
categories: 操作系统
---

# 2021.12.4
## 系统调用
可以把进程在系统上的运行分为两个级别：
1. **用户态**(user mode) : 用户态运行的进程可以直接读取用户程序的数据。
2. **内核态**(kernel mode):可以简单的理解系统态运行的进程或程序几乎可以访问计算机的任何资源，不受限制

我们运行的程序基本都是运行在用户态，如果我们调用操作系统提供的系统态级别的子功能，那就要用到**系统调用**。
也就是说在我们运行的用户程序中，凡是与系统态级别的资源有关的操作（如文件管理、进程控制、内存管理等)，都必须通过系统调用方式向操作系统提出服务请求，并由操作系统代为完成。

系统调用的种类：
- **设备管理**：完成设备的请求或释放，以及设备启动等功能。
- **文件管理**：完成文件的读、写、创建及删除等功能。
- **进程控制**：完成进程的创建、撤销、阻塞及唤醒等功能。
- **进程通信**：完成进程之间的消息传递或信号传递等功能。
- **内存管理**：完成内存的分配、回收以及获取作业占用内存区大小及地址等功能。

## 快表和多级页表

### 快表
为了解决虚拟地址到物理地址的转换速度，操作系统在 **页表方案** 基础之上引入了 **快表** 来加速虚拟地址到物理地址的转换。我们可以把快表理解为一种**特殊的高速缓冲存储器**（Cache），其中的内容是页表的一部分或者全部内容。作为页表的 Cache，它的作用与页表相似，但是提高了访问速率。由于采用页表做地址转换，读写内存数据时 CPU 要访问两次主存。有了快表，有时只要访问一次高速缓冲存储器，一次主存，这样可加速查找并提高指令执行速度。

使用快表之后的地址转换流程是这样的：
1. 根据虚拟地址中的页号查快表；
2. 如果该页在快表中，直接从快表中读取相应的物理地址；
3. 如果该页不在快表中，就访问内存中的页表，再从页表中得到物理地址，同时将页表中的该映射表项添加到快表中；
4. 当快表填满后，又要登记新页时，就按照一定的淘汰策略淘汰掉快表中的一个页。

### 多级页表
引入多级页表的主要目的是为了避免把全部页表一直放在内存中占用过多空间，特别是那些根本就不需要的页表就不需要保留在内存中。

总结来说：
为了提高内存的空间性能，提出了多级页表的概念；但是提到空间性能是以浪费时间性能为基础的，因此为了补充损失的时间性能，提出了快表（即 TLB）的概念。

## 逻辑(虚拟)地址和物理地址
我们编程一般只有可能和逻辑地址打交道，比如在 C 语言中，指针里面存储的数值就可以理解成为内存里的一个地址，这个地址也就是我们说的**逻辑地址**，逻辑地址由操作系统决定。**物理地址**指的是真实物理内存中地址，更具体一点来说就是内存地址寄存器中的地址。物理地址是内存单元真正的地址。

## CPU 寻址 
现代处理器使用的是一种称为 **虚拟寻址**的寻址方式。**使用虚拟寻址，CPU 需要将虚拟地址翻译成物理地址，这样才能访问到真实的物理内存。** 实际上完成虚拟地址转换为物理地址转换的硬件是 CPU 中含有一个被称为 **内存管理单元** 的硬件。

**为什么要有虚拟地址空间呢？**
如果直接把物理地址暴露出来的话会带来严重问题，比如可能对操作系统造成伤害以及给同时运行多个程序造成困难。

通过虚拟地址访问内存有以下优势：
· 程序可以使用一系列相邻的虚拟地址来访问物理内存中不相邻的大内存缓冲区。
· 程序可以使用一系列虚拟地址来访问大于可用物理内存的内存缓冲区。当物理内存的供应量变小时，内存管理器会将物理内存页（通常大小为 4 KB）保存到磁盘文件。数据或代码页会根据需要在物理内存与磁盘之间移动。
· 不同进程使用的虚拟地址彼此隔离。一个进程中的代码无法更改正在由另一进程或操作系统使用的物理内存。

## 什么是虚拟内存
很多时候我们使用点开了很多占内存的软件，这些软件占用的内存可能已经远远超出了我们电脑本身具有的物理内存。为什么可以这样呢？ 正是因为 **虚拟内存** 的存在，通过 **虚拟内存** 可以让程序可以拥有超过系统物理内存大小的可用内存空间。另外，**虚拟内存为每个进程提供了一个一致的、私有的地址空间，它让每个进程产生了一种自己在独享主存的错觉（每个进程拥有一片连续完整的内存空间）**。这样会更加有效地管理内存并减少出错。

# 2021.12.8
## 局部性原理
局部性原理是虚拟内存技术的基础，正是因为程序运行具有局部性原理，才可以只装入部分程序到内存就开始运行。

局部性原理表现在以下两个方面：
- **时间局部性** ：如果程序中的某条指令一旦执行，不久以后该指令可能再次执行；如果某数据被访问过，不久以后该数据可能再次被访问。产生时间局部性的典型原因，是由于在程序中存在着大量的**循环操作**。
- **空间局部性** ：一旦程序访问了某个存储单元，在不久之后，其附近的存储单元也将被访问，即**程序在一段时间内所访问的地址**，可能**集中在一定的范围之内**，这是因为指令通常是顺序存放、顺序执行的，数据也一般是以向量、数组、表等形式簇聚存储的。

# 2021.12.9
## 虚拟内存技术的实现
虚拟内存的实现需要建立在**离散分配的内存管理方式**的基础上，虚拟内存的实现有以下三种方式：
1. **请求分页存储管理** ：建立在分页管理之上，为了支持虚拟存储器功能而增加了请求调页功能和页面置换功能。请求分页是目前最常用的一种实现虚拟存储器的方法。请求分页存储管理系统中，在作业开始运行之前，仅装入当前要执行的部分段即可运行。假如在作业运行的过程中发现要访问的页面不在内存，则由处理器通知操作系统按照对应的页面置换算法将相应的页面调入到主存，同时操作系统也可以将暂时不用的页面置换到外存中。 
2. **请求分段存储管理** ：建立在分段存储管理之上，增加了请求调段功能、分段置换功能。请求分段储存管理方式就如同请求分页储存管理方式一样，在作业开始运行之前，仅装入当前要执行的部分段即可运行；在执行过程中，可使用请求调入中断动态装入要访问但又不在内存的程序段；当内存空间已满，而又需要装入新的段时，根据置换功能适当调出某个段，以便腾出空间而装入新的段。
3. **请求段页式存储管理** ：...

不管是上面那种实现方式，我们一般都需要：
1. 一定容量的内存和外存 ：在载入程序的时候，只需要将程序的一部分装入内存，而将其他部分留在外存，然后程序就可以执行了；
2. **缺页中断** ：如果需执行的指令或访问的数据尚未在内存（称为缺页或缺段），则由处理器通知操作系统将相应的页面或段调入到内存，然后继续执行程序；
3. **虚拟地址空间** ：逻辑地址到物理地址的变换。

## 页面置换算法
地址映射过程中，若在页面中发现所要访问的页面不在内存中，则发生缺页中断。
- **OPT 页面置换算法（最佳页面置换算法）** ：最佳(Optimal, OPT)置换算法所选择的被淘汰页面将是以后永不使用的，或者是在最长时间内不再被访问的页面,这样可以保证获得最低的缺页率。但由于人们目前无法预知进程在内存下的若千页面中哪个是未来最长时间内不再被访问的，因而该算法无法实现。一般作为衡量其他置换算法的方法。
- **FIFO（First In First Out） 页面置换算法（先进先出页面置换算法）** : 总是淘汰最先进入内存的页面，即选择在内存中驻留时间最久的页面进行淘汰。
- **LRU （Least Recently Used）页面置换算法（最近最久未使用页面置换算法）** ：LRU算法赋予每个页面一个访问字段，用来记录一个页面自上次被访问以来所经历的时间 T，当须淘汰一个页面时，选择现有页面中其 T 值最大的，即最近最久未使用的页面予以淘汰。
- **LFU （Least Frequently Used）页面置换算法（最少使用页面置换算法）** : 该置换算法选择在之前时期使用最少的页面作为淘汰页。

# 2022.8.29

## 用户态和内核态的实现

### 用户态和内核态是怎么实现的？

CPU中含有三个寄存器分别是：**特权寄存器**、**用户寄存器**和**模式状态寄存器**。

CPU有两种不同的指令：**特权指令**和非特权指令。

1. 特权指令是需要在特权寄存器上运行的
2. 非特权指令是需要在用户寄存器下运行的

操作系统通过控制**模式状态寄存器**来决定程序在用户区还是内核区进行执行的。然而特权与非特权是由模式状态寄存器控制的，**只要CPU控制了模式状态寄存器就可以控制程序在哪个寄存器上运行**。这也就是用户态和内核态的实现。

### 用户态切换到内核态的方式

1. 系统调用（用户进行主动发出，比如调用函数（printf）之类的）

2. 异常（缺页中断）

3. 外围设备的中断

### 假设发生缺页中断后，执行什么？

当一个进程发生缺页中断，进程会立马陷入到内核态

1. 检查要访问的虚拟地址是否合法

2. 查找、分配一个物理页

3. 填充物理页内容

4. 建立映射关系

重新回到发生缺页中断那条指令

## 如何在 Windows 和 Linux 上查找哪个线程cpu利用率最高？

windows上面用任务管理器看，linux下可以用 top 这个工具看。

1. 找出cpu耗用厉害的进程pid， 终端执行top命令，然后按下shift+p 查找出cpu利用最厉害的pid号
2. 根据上面第一步拿到的pid号，top -H -p pid 。然后按下shift+p，查找出cpu利用率最厉害的线程号，比如top -H -p 1328
3. 将获取到的线程号转换成16进制，去百度转换一下就行
4. 使用jstack工具将进程信息打印输出，jstack pid号 > /tmp/t.dat，比如jstack 31365 > /tmp/t.dat
5. 编辑/tmp/t.dat文件，查找线程号对应的信息

## 5种IO模型

应用程序发起的一次IO操作包含两个阶段：

- IO调用：应用程序进程向操作系统**内核**发起调用。

- IO执行：操作系统内核完成IO操作。

操作系统内核完成IO操作还包括两个过程：

- 准备数据阶段：内核等待I/O设备准备好数据
- 拷贝数据阶段：将数据从内核缓冲区拷贝到用户进程缓冲区

<img src="https://carbda-bucket.oss-cn-hangzhou.aliyuncs.com/img/os1.png" style="zoom:80%;" />

### 阻塞IO模型

假设应用程序的进程发起**IO调用**，但是如果**内核的数据还没准备好**的话，那应用程序进程就一直在**阻塞等待**，一直等到内核数据准备好了，从内核拷贝到用户空间，才返回成功提示，此次IO操作，称之为**阻塞IO**。

<img src="https://carbda-bucket.oss-cn-hangzhou.aliyuncs.com/img/os2.png" style="zoom:80%;" />

### 非阻塞IO模型

如果内核数据还没准备好，可以先返回错误信息给用户进程，让它不需要等待，而是通过轮询的方式再来请求。这就是非阻塞IO，流程图如下：

<img src="https://carbda-bucket.oss-cn-hangzhou.aliyuncs.com/img/os3.png" style="zoom:80%;" />

非阻塞IO的流程如下：

- 应用进程向操作系统内核，发起recvfrom读取数据。

- 操作系统内核数据没有准备好，立即返回EWOULDBLOCK错误码。
- 应用程序进程轮询调用，继续向操作系统内核发起recvfrom读取数据。
- 操作系统内核数据准备好了，从内核缓冲区拷贝到用户空间。
- 完成调用，返回成功提示。

非阻塞IO模型，简称**NIO**，Non-Blocking IO。它相对于阻塞IO，虽然大幅提升了性能，但是它依然存在**性能问题**，即**频繁的轮询**，导致频繁的系统调用，同样会消耗大量的CPU资源。可以考虑**IO复用模型**，去解决这个问题。

### IO多路复用模型

既然**NIO**无效的轮询会导致CPU资源消耗，我们等到内核数据准备好了，主动通知应用进程再去进行系统调用，那不就好了嘛？

在这之前，我们先来复习下，什么是**文件描述符fd**(File Descriptor),它是计算机科学中的一个术语，形式上是一个非负整数。当程序打开一个现有文件或者创建一个新文件时，内核向进程返回一个文件描述符。

IO复用模型核心思路：系统给我们提供**一类函数**（如我们耳濡目染的**select、poll、epoll**函数），它们可以同时监控多个fd的操作，任何一个返回内核数据就绪，应用进程再发起recvfrom系统调用。

#### select

应用进程通过调用**select**函数，可以同时监控多个fd，在select函数监控的fd中，只要有任何一个数据状态准备就绪了，select函数就会返回可读状态，这时应用进程再发起recvfrom请求去读取数据。

<img src="https://carbda-bucket.oss-cn-hangzhou.aliyuncs.com/img/os4.png" style="zoom:80%;" />

非阻塞IO模型（NIO）中，需要N（N>=1）次轮询系统调用，然而借助select的IO多路复用模型，只需要发起一次询问就够了,大大优化了性能。

但是呢，select有几个缺点：

- 监听的IO最大连接数有限，在Linux系统上一般为1024。
- select函数返回后，是通过**遍历**fdset，找到就绪的描述符fd。（仅知道有I/O事件发生，却不知是哪几个流，所以**遍历所有流**）

因为**存在连接数限制**，所以后来又提出了**poll**。与select相比，**poll**解决了**连接数限制问题**。但是呢，select和poll一样，还是需要通过遍历文件描述符来获取已经就绪的socket。如果同时连接的大量客户端，在一时刻可能只有极少处于就绪状态，伴随着监视的描述符数量的增长，**效率也会线性下降**。

#### epoll

为了解决select/poll存在的问题，多路复用模型epoll诞生，它采用**事件驱动**来实现

<img src="https://carbda-bucket.oss-cn-hangzhou.aliyuncs.com/img/os5.png" style="zoom:80%;" />

**epoll**先通过epoll_ctl()来注册一个fd（文件描述符），一旦基于某个fd就绪时，内核会采用回调机制，迅速激活这个fd，当进程调用epoll_wait()时便得到通知。这里去掉了**遍历文件描述符**的操作，而是采用**监听事件回调**的机制。这就是epoll的亮点。

总结一下：

![](https://carbda-bucket.oss-cn-hangzhou.aliyuncs.com/img/os6.png)

### 信号驱动模型

信号驱动IO不再用主动询问的方式去确认数据是否就绪，而是向内核发送一个信号（调用sigaction的时候建立一个SIGIO的信号），然后应用用户进程可以去做别的事，不用阻塞。当内核数据准备好后，再通过SIGIO信号通知应用进程，数据准备好后的可读状态。应用用户进程收到信号之后，立即调用recvfrom，去读取数据。

<img src="https://carbda-bucket.oss-cn-hangzhou.aliyuncs.com/img/os7.png" style="zoom:80%;" />

### 异步IO(AIO)

前面讲的BIO，NIO和信号驱动，在数据从内核复制到应用缓冲的时候，都是**阻塞**的，因此都不算是真正的异步。AIO实现了IO全流程的非阻塞，就是应用进程发出系统调用后，是立即返回的，但是**立即返回的不是处理结果，而是表示提交成功类似的意思**。等内核数据准备好，将数据拷贝到用户进程缓冲区，发送信号通知用户进程IO操作执行完毕。

<img src="https://carbda-bucket.oss-cn-hangzhou.aliyuncs.com/img/os8.png" style="zoom:80%;" />

异步IO的优化思路很简单，只需要向内核发送一次请求，就可以完成数据状态询问和数据拷贝的所有操作，并且不用阻塞等待结果。
